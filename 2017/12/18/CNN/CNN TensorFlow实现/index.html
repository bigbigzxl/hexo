<!DOCTYPE html>

<html class="theme-next pisces use-motion" lang="zh-Hans">

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"
  />
  <meta name="theme-color" content="#222">

  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />

  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"
  />

  <link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet"
                                                                                  type="text/css" />

  <link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">

  <link rel="icon" type="image/png" sizes="32x32" href="/images/32x32.png?v=5.1.3">

  <link rel="icon" type="image/png" sizes="16x16" href="/images/16x16.png?v=5.1.3">

  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">

  <meta name="keywords" content="Hexo, ZXL" />

  <meta name="description" content="说起CNN的模型图，要从经典CNN的相关paper开始：           CNN综述必须拜读啊！              学习资源在这              本文搬移至这        LeNet，1998年（开山鼻祖）；    卷积   非线性(ReLU)   池化或下采样   分类（全连接层）       理解滤波器（卷积核）对于原输入图片来说，是个特征探测器。对于同一张照片，不同的">
  <meta property="og:type" content="article">
  <meta property="og:title" content="CNN TensorFlow实现">
  <meta property="og:url" content="http://www.jianshu.com/u/a08f88f9ed9d/2017/12/18/CNN/CNN TensorFlow实现/index.html">
  <meta property="og:site_name" content="十曰立">
  <meta property="og:description" content="说起CNN的模型图，要从经典CNN的相关paper开始：           CNN综述必须拜读啊！              学习资源在这              本文搬移至这        LeNet，1998年（开山鼻祖）；    卷积   非线性(ReLU)   池化或下采样   分类（全连接层）       理解滤波器（卷积核）对于原输入图片来说，是个特征探测器。对于同一张照片，不同的">
  <meta property="og:locale" content="zh-Hans">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-b96b426c08c8d699.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-49c8f504494473e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-6053bdf6838e66ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-121c692f875600f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-6421db9ebbc4bfa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-4c54f1099461d5b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-beea7a88932f2f03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-ca46e92debab1a4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-a6469df9b8c45340.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-53564fae9ccba3c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:image" content="http://upload-images.jianshu.io/upload_images/4749583-a8737898b4a0c8f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  <meta property="og:updated_time" content="2017-12-18T07:52:54.330Z">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="CNN TensorFlow实现">
  <meta name="twitter:description" content="说起CNN的模型图，要从经典CNN的相关paper开始：           CNN综述必须拜读啊！              学习资源在这              本文搬移至这        LeNet，1998年（开山鼻祖）；    卷积   非线性(ReLU)   池化或下采样   分类（全连接层）       理解滤波器（卷积核）对于原输入图片来说，是个特征探测器。对于同一张照片，不同的">
  <meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/4749583-b96b426c08c8d699.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">

  <script type="text/javascript" id="hexo.configurations">
    var NexT = window.NexT || {};
    var CONFIG = {
      root: '/',
      scheme: 'Pisces',
      version: '5.1.3',
      sidebar: {
        "position": "left",
        "display": "post",
        "offset": 12,
        "b2t": false,
        "scrollpercent": false,
        "onmobile": false
      },
      fancybox: true,
      tabs: true,
      motion: {
        "enable": true,
        "async": false,
        "transition": {
          "post_block": "fadeIn",
          "post_header": "slideDownIn",
          "post_body": "slideDownIn",
          "coll_header": "slideLeftIn",
          "sidebar": "slideUpIn"
        }
      },
      duoshuo: {
        userId: '0',
        author: '博主'
      },
      algolia: {
        applicationID: '',
        apiKey: '',
        indexName: '',
        hits: {
          "per_page": 10
        },
        labels: {
          "input_placeholder": "Search for Posts",
          "hits_empty": "We didn't find any results for the search: ${query}",
          "hits_stats": "${hits} results found in ${time} ms"
        }
      }
    };

  </script>

  <link rel="canonical" href="http://www.jianshu.com/u/a08f88f9ed9d/2017/12/18/CNN/CNN TensorFlow实现/"
  />

  <title>CNN TensorFlow实现 | 十曰立</title>

</head>

<div id="hexo-helper-live2d">
  <canvas id="live2dcanvas" width="150" height="300"></canvas>
</div>
<style>
  #live2dcanvas {
    position: fixed;
    width: 150px;
    height: 300px;
    opacity: 0.7;
    right: 0px;
    z-index: 999;
    pointer-events: none;
    bottom: -20px;
  }

</style>
<script type="text/javascript" src="/live2d/device.min.js"></script>
<script type="text/javascript">
  const loadScript = function loadScript(c, b) {
    var a = document.createElement("script");
    a.type = "text/javascript";
    "undefined" != typeof b && (a.readyState ? a.onreadystatechange =
      function() {
        if ("loaded" == a.readyState || "complete" == a.readyState) a.onreadystatechange =
          null, b()
      } : a.onload = function() {
        b()
      });
    a.src = c;
    document.body.appendChild(a)
  };
  (function() {
    if ((typeof(device) != 'undefined') && (device.mobile())) {
      document.getElementById("live2dcanvas").style.width = '75px';
      document.getElementById("live2dcanvas").style.height = '150px';
    } else
    if (typeof(device) === 'undefined') console.error(
      'Cannot find current-device script.');
    loadScript("/live2d/script.js", function() {
      loadlive2d("live2dcanvas", "/live2d/assets/hijiki.model.json", 0.5);
    });
  })();

</script>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/bigbigzxl">
      <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67"
                                                                                      alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png">
    </a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner">
        <div class="site-brand-wrapper">
          <div class="site-meta custom-logo">

            <div class="custom-logo-site-title">
              <a href="/" class="brand" rel="start">
                <span class="logo-line-before">
                  <i></i>
                </span>
                <span class="site-title">十曰立</span>
                <span class="logo-line-after">
                  <i></i>
                </span>
              </a>
            </div>

            <p class="site-subtitle">每日十立其身</p>

          </div>

          <div class="site-nav-toggle">
            <button>
              <span class="btn-bar"></span>
              <span class="btn-bar"></span>
              <span class="btn-bar"></span>
            </button>
          </div>
        </div>

        <nav class="site-nav">

          <ul id="menu" class="menu">

            <li class="menu-item menu-item-home">
              <a href="/" rel="section">

                <i class="menu-item-icon fa fa-fw fa-home"></i>
                <br /> 首页
              </a>
            </li>

            <li class="menu-item menu-item-categories">
              <a href="/categories/" rel="section">

                <i class="menu-item-icon fa fa-fw fa-heart"></i>
                <br /> 分类
              </a>
            </li>

          </ul>

        </nav>

      </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">

            <div id="posts" class="posts-expand">

              <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">

                <div class="post-block">
                  <link itemprop="mainEntityOfPage" href="http://www.jianshu.com/u/a08f88f9ed9d/2017/12/18/CNN/CNN TensorFlow实现/">

                  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
                    <meta itemprop="name" content="十曰立">
                    <meta itemprop="description" content="">
                    <meta itemprop="image" content="/images/avatar.png">
                  </span>

                  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                    <meta itemprop="name" content="十曰立">
                  </span>

                  <header class="post-header">

                    <h1 class="post-title" itemprop="name headline">CNN TensorFlow实现</h1>

                    <div class="post-meta">
                      <span class="post-time">

                        <span class="post-meta-item-icon">
                          <i class="fa fa-calendar-o"></i>
                        </span>

                        <span class="post-meta-item-text">发表于</span>

                        <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-18T15:51:58+08:00">
                          2017-12-18
                        </time>

                      </span>

                      <span class="post-category">

                        <span class="post-meta-divider">|</span>

                        <span class="post-meta-item-icon">
                          <i class="fa fa-folder-o"></i>
                        </span>

                        <span class="post-meta-item-text">分类于</span>

                        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                          <a href="/categories/CNN/" itemprop="url" rel="index">
                            <span itemprop="name">CNN</span>
                          </a>
                        </span>

                      </span>

                      <div class="post-wordcount">

                        <span class="post-meta-item-icon">
                          <i class="fa fa-file-word-o"></i>
                        </span>

                        <span class="post-meta-item-text">字数统计&#58;</span>

                        <span title="字数统计">
                          3,304
                        </span>

                        <span class="post-meta-divider">|</span>

                        <span class="post-meta-item-icon">
                          <i class="fa fa-clock-o"></i>
                        </span>

                        <span class="post-meta-item-text">阅读时长 &asymp;</span>

                        <span title="阅读时长">
                          12
                        </span>

                      </div>

                    </div>
                  </header>

                  <div class="post-body" itemprop="articleBody">

                    <p>说起CNN的模型图，要从经典CNN的相关paper开始：
                      <br>
                      <a href="https://chenzomi12.github.io/2016/12/13/CNN-Architectures/" target="_blank"
                                                                                                      rel="external">
                        <strong>CNN综述必须拜读啊！</strong>
                      </a>
                      <br>
                      <a href="https://jizhi.im/community/discuss/2017-03-13-10-9-2-pm" target="_blank"
                                                                                                      rel="external">
                        <strong>学习资源在这</strong>
                      </a>
                      <br>
                      <a href="https://zhuanlan.zhihu.com/p/25754846" target="_blank" rel="external">
                        <strong>本文搬移至这</strong>
                      </a>
                    </p>
                    <h1 id="LeNet，1998年（开山鼻祖）；">
                      <a href="#LeNet，1998年（开山鼻祖）；" class="headerlink" title="LeNet，1998年（开山鼻祖）；"></a>LeNet，1998年（开山鼻祖）；</h1>
                    <ul>
                      <li>卷积</li>
                      <li>非线性(ReLU)</li>
                      <li>池化或下采样</li>
                      <li>分类（全连接层）</li>
                    </ul>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-b96b426c08c8d699.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="简单的ConvNet">
                    </p>
                    <p>理解滤波器（卷积核）对于原输入图片来说，是个特征探测器。对于同一张照片，不同的滤波器将会产生不同的特征映射。</p>
                    <blockquote>
                      <p>
                        <strong>卷积神经网络与我们之前所学到的图像的卷积的区别：我们之前学图像处理遇到卷积，一般来说，这个卷积核是已知的，比如各种边缘检测算子、高斯模糊等这些，都是已经知道卷积核，然后再与图像进行卷积运算。然而深度学习中的卷积神经网络卷积核是未知的，我们训练一个神经网络，就是要训练得出这些卷积核，而这些卷积核就相当于我们学单层感知器的时候的那些参数W，因此你可以把这些待学习的卷积核看成是神经网络的训练参数W。</strong>
                      </p>
                      <p>在CNN中，我们要训练的卷积核并不是仅仅只有一个，这些卷积核用于提取特征，卷积核个数越多，提取的特征越多，理论上来说精度也会更高，然而卷积核一堆，意味着我们要训练的参数的个数越多。在LeNet-5经典结构中，第一层卷积核选择了6个，而在AlexNet中，第一层卷积核就选择了96个，
                        <strong>具体多少个合适，还有待学习。</strong>
                      </p>
                      <p>回到特征图(feature maps 也即卷积后的图片)概念，
                        <strong>CNN的每一个卷积层我们都要人为的选取合适的卷积核个数，及卷积核大小。</strong>每个卷积核与图片进行卷积，就可以得到一张特征图了，比如LeNet-5经典结构中，第一层卷积核选择了6个，我们可以得到6个特征图，这些特征图也就是下一层网络的输入了。我们也可以把输入图片看成一张特征图，作为第一层网络的输入。</p>
                    </blockquote>
                    <p>4、CNN的经典结构
                      <br>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-49c8f504494473e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="不同卷积核的效果">
                    </p>
                    <p>在实践当中，卷积神经网络在训练过程中学习滤波器的值，当然我们还是要在训练之前需要指定一些参数：</p>
                    <ul>
                      <li>滤波器的个数，滤波器尺寸、网络架构等等。</li>
                      <li>滤波器越多，从图像中提取的特征就越多，模式识别能力就越强。</li>
                    </ul>
                    <p>特征映射的尺寸由三个参数控制，我们需要在卷积步骤之前就设定好：
                      <br>
                      <strong>深度(Depth)</strong>： 深度就是卷积操作中用到的滤波器个数。如下图所示，我们对原始的船图用了三个不同的滤波器，从而产生了三个特征映射。你可以认为这三个特征映射也是堆叠的2d矩阵，所以这里特征映射的“深度”就是3。</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-6053bdf6838e66ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="">
                    </p>
                    <p>
                      <strong>步幅(Stride)</strong>：步幅是每次滑过的像素数。当Stride=1的时候就是逐个像素地滑动。当Stride=2的时候每次就会滑过2个像素。步幅越大，特征映射越小。</p>
                    <p>
                      <strong>补零(Zero-padding)</strong>：有时候在输入矩阵的边缘填补一圈0会很方便，这样我们就可以对图像矩阵的边缘像素也施加滤波器。补零的好处是让我们可以控制特征映射的尺寸。补零也叫宽卷积，不补零就叫窄卷积。</p>
                    <h3 id="非线性：">
                      <a href="#非线性：" class="headerlink" title="非线性："></a>
                      <strong>非线性</strong>：</h3>
                    <p>ReLU是以像素为单位生效的，其将所有负值像素替换为0。ReLU的目的是向卷积网络中引入非线性，因为真实世界里大多数需要学习的问题都是非线性的（单纯的卷积操作时线性的——矩阵相乘、相加，所以才需要额外的计算引入非线性）。</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-121c692f875600f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="ReLU">
                    </p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-6421db9ebbc4bfa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="">
                    </p>
                    <p>其实可以这么理解，大于0的都是关心的数据，小于0的是不关心的数据，因此直接小于0的去掉，符合人的基本逻辑感知。
                      <br>其他非线性方程比如tanh或sigmoid也可以替代ReLU，但大家一般都用ReLU。</p>
                    <h3 id="池化">
                      <a href="#池化" class="headerlink" title="池化"></a>池化</h3>
                    <p>简单来说就是把图片降size的，降低处理量嘛；空间池化（也叫亚采样或下采样）降低了每个特征映射的维度，但是保留了最重要的信息。空间池化可以有很多种形式：最大(Max)，平均(Average)，求和(Sum)等等。</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-4c54f1099461d5b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="">
                    </p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-beea7a88932f2f03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="池化效果">
                    </p>
                    <p>池化的功能逐步减少输入表征的空间尺寸。特别地，池化</p>
                    <ul>
                      <li>使输入表征（特征维度）更小而易操作</li>
                      <li>减少网络中的参数与计算数量，从而遏制过拟合</li>
                      <li>增强网络对输入图像中的小变形、扭曲、平移的鲁棒性（输入里的微小扭曲不会改变池化输出——因为我们在局部邻域已经取了最大值/平均值）。</li>
                      <li>帮助我们获得不因尺寸而改变的等效图片表征。这非常有用，因为这样我们就可以探测到图片里的物体，不论那个物体在哪。</li>
                    </ul>
                    <h3 id="全连接层">
                      <a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3>
                    <p>全连接层(Fully Connected layer)就是使用了softmax激励函数作为输出层的多层感知机(Multi-Layer
                      Perceptron)，其他很多分类器如支持向量机也使用了softmax。</p>
                    <p>“全连接”表示上一层的每一个神经元，都和下一层的每一个神经元是相互连接的。</p>
                    <p>到目前为止，前面的一些卷积、非线性、池化操作就已经把特征给选出来了，而且是
                      <strong>高级特征</strong>哟，这个时候用感知机那一套就可以实现拟合了嘛，由于我们实际场景可能是多分类问题，因此我们用的是softmax。</p>
                    <p>除了分类以外，加入全连接层也是学习特征之间非线性组合的有效办法。卷积层和池化层提取出来的特征很好，但是如果考虑这些特征之间的组合，就更好了。</p>
                    <p>全连接层的输出概率之和为1，这是由激励函数Softmax保证的。Softmax函数把任意实值的向量转变成元素取之0-1且和为1的向量。</p>
                    <h3 id="得开始训练啦！！！">
                      <a href="#得开始训练啦！！！" class="headerlink" title="得开始训练啦！！！"></a>得开始训练啦！！！</h3>
                    <p>从前面可知
                      <strong>卷积+池化是特征提取器，全连接层是分类器</strong>。</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-ca46e92debab1a4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="训练CNN">
                    </p>
                    <p>如上因为输入的图片是船，因此最后的结果向量是[0,0,1,0]。</p>
                    <p>
                      <strong>训练过程如下：</strong>
                    </p>
                    <ol>
                      <li>用随机数初始化所有的
                        <strong>滤波器和参数/权重</strong>。</li>
                      <li>输入图片，前向执行
                        <strong>卷积、ReLU、池化及全连接的前向传播，并计算出每个类别对应的输出概率</strong>。
                        <ul>
                          <li>假设船图的输出概率是[0.2, 0.4, 0.1, 0.3]</li>
                          <li>因为第一个训练样本的权重都是
                            <strong>随机</strong>的，所以这个输出概率也跟随机的差不多.</li>
                        </ul>
                      </li>
                      <li>计算输出层的总误差（
                        <strong>4类别之和</strong>）:这用的是均方误差！
                        <strong>MSE</strong>！
                        <br>Total Error = ∑ ½ (target probability – output probability)
                        ²</li>
                      <li>反向传播用总的误差，来计算每个权重的梯度并更新之，也就是我们眼光放到全局来做宏观调控，具体的“政策”细节参数则由上到下反过来一个一个调节。
                        <ul>
                          <li>权重的调整程度与其
                            <strong>对总误差的贡献</strong>成正比。</li>
                          <li>当
                            <strong>同一图像</strong>再次被输入，这次的输出概率可能是[0.1, 0.1, 0.7, 0.1]，与目标[0,
                            0, 1, 0]更接近了。</li>
                          <li>这说明我们的神经网络已经学习着分类特定图片了，学习的方式是调整权重/滤波器以降低输出误差。</li>
                          <li>如果滤波器个数、滤波器尺寸、网络架构这些参数，是在第一步之前就已经固定的，且不会在训练过程中改变（也就是这个网络结构可以随意改？）——只有卷积核跟全连接网络的权重会更新。</li>
                        </ul>
                      </li>
                    </ol>
                    <blockquote>
                      <p>上述步骤总结起来就是：
                        <strong>优化所有的权重和参数，使其能够正确地分类训练集里的图片。</strong>
                      </p>
                    </blockquote>
                    <p>上例中，我们用了两组卷积+池化层，其实这些操作可以在一个卷积网络内重复无数次。
                      <strong>如今有些表现出众的卷积网络，都有数以十计的卷积+池化层！并且，不是每个卷积层后面都要跟个池化层。</strong>由下图可见，我们可以有连续多组卷积+ReLU层，后面再加一个池化层。</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-a6469df9b8c45340.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="">
                    </p>
                    <h2 id="gt-小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事，客官请移步">
                      <a href="#gt-小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事，客官请移步" class="headerlink"
                                                                                                      title="&gt;小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事，客官请移步!"></a>&gt;小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事，
                      <a href="https://zhuanlan.zhihu.com/p/25774111" target="_blank" rel="external">
                        <strong>客官请移步!</strong>
                      </a>
                    </h2>
                    <h1 id="可视化卷积神经网络">
                      <a href="#可视化卷积神经网络" class="headerlink" title="可视化卷积神经网络"></a>可视化卷积神经网络</h1>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-53564fae9ccba3c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="Convolutional Deep Belief Network学习的特征">
                    </p>
                    <p>一般来说，卷积层越多，能学会的特征也就越复杂。比如在图像分类中，一个卷积神经网络的第一层学会了探测像素中的边缘，然后第二层用这些边缘再去探测简单的形状，其他层再用形状去探测高级特征，比如脸型，如
                      <strong>图17</strong>所示——这些特征是
                      <a href="http://link.zhihu.com/?target=http%3A//web.eecs.umich.edu/%7Ehonglak/icml09-ConvolutionalDeepBeliefNetworks.pdf"
                                                                                                      target="_blank" rel="external">Convolutional Deep Belief Network**</a>学得的。这里只是一个简单的例子，实际上卷积滤波器可能会探测出一些
                      <strong>没有意义的特征</strong>。</p>
                    <p>#其他卷积网络架构
                      <br>卷积神经网络始自1990年代起，我们已经认识了最早的LeNet，其他一些很有影响力的架构列举如下：</p>
                    <blockquote>
                      <p>1990s至2012：从90年代到2010年代早期，卷积神经网络都处于孵化阶段。随着数据量增大和计算能力提高，卷积神经网络能搞定的问题也越来越有意思了。</p>
                    </blockquote>
                    <ul>
                      <li>
                        <p>AlexNet(2012)：2012年，Alex Krizhevsky发布了
                          <a href="http://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"
                                                                                                          target="_blank" rel="external">AlexNet**</a>，是LeNet的更深、更宽版本，并且大比分赢得了当年的ImageNet大规模图像识别挑战赛(ILSVRC)。这是一次非常重要的大突破，现在普及的卷积神经网络应用都要感谢这一壮举。</p>
                      </li>
                      <li>
                        <p>ZF Net(2013)：2013年的ILSVRC赢家是Matthew Zeiler和Rob Fergus的卷积网络，被称作
                          <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1311.2901" target="_blank"
                                                                                                          rel="external">ZF Net**</a>，这是调整过架构超参数的AlexNet改进型。</p>
                      </li>
                      <li>
                        <p>GoogleNet(2014)：2014的ILSVRC胜者是来自Google的
                          <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.4842" target="_blank"
                                                                                                          rel="external">Szegedy et al.**</a>。其主要贡献是研发了
                          <em>Inception Module</em>，它大幅减少了网络中的参数数量（四百万，相比AlexNet的六千万）。</p>
                      </li>
                      <li>
                        <p>VGGNet(2014)：当年的ILSVRC亚军是
                          <a href="http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/"
                                                                                                          target="_blank" rel="external">VGGNet**</a>，突出贡献是展示了网络的深度（层次数量）是良好表现的关键因素。</p>
                      </li>
                      <li>
                        <p>ResNet(2015)： Kaiming He研发的
                          <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1512.03385" target="_blank"
                                                                                                          rel="external">Residual Network**</a>是2015年的ILSVRC冠军，也代表了卷积神经网络的最高水平，同时还是实践的默认选择（2016年5月）。</p>
                      </li>
                      <li>
                        <p>DenseNet（2016年8月）： 由Gao Huang发表，
                          <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1608.06993" target="_blank"
                                                                                                          rel="external">Densely Connected Convolutional Network**</a>的每一层都直接与其他各层前向连接。DenseNet已经在五个高难度的物体识别基础集上，显式出非凡的进步。</p>
                        <figure class="highlight plain">
                          <table>
                            <tr>
                              <td class="gutter">
                                <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre>
                              </td>
                              <td class="code">
                                <pre><span class="line">AlexNet，2012年 ；</span><br><span class="line">ZF-net，2013年；</span><br><span class="line">NIN，2013年；</span><br><span class="line">GoogLeNet (InceptionV1)，2014年；</span><br><span class="line">VGG，2014年；</span><br><span class="line">Batch Norm (InceptionV2)，2015年；</span><br><span class="line">InceptionV3 ，2015年；</span><br><span class="line">ResNet，2015年；</span><br><span class="line">InceptionV4，2016年。</span><br></pre>
                              </td>
                            </tr>
                          </table>
                        </figure>
                      </li>
                    </ul>
                    <hr>
                    <h1 id="LeNet-5实现（TensorFlow）">
                      <a href="#LeNet-5实现（TensorFlow）" class="headerlink" title="LeNet-5实现（TensorFlow）"></a>LeNet-5实现（TensorFlow）</h1>
                    <p>LeNet-5是用于手写字体的识别的一个经典CNN：</p>
                    <p>
                      <img src="http://upload-images.jianshu.io/upload_images/4749583-a8737898b4a0c8f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                                                                                                      alt="">
                    </p>
                    <p>
                      <strong>输入：</strong> 32*32的手写字体图片，这些手写字体包含0~9数字，我们可以从官网上下载标准的minist数据集（TF包里面自带下载函数的，是通过read_data_sets（）函数里面的下载函数下载的。）</p>
                    <figure class="highlight python">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="meta">@retry(initial_delay=1.0, max_delay=16.0, is_retriable=_is_retriable)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">urlretrieve_with_retry</span><span class="params">(url, filename=None)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> urllib.request.urlretrieve(url, filename)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybe_download</span><span class="params">(filename, work_directory, source_url)</span>:</span></span><br><span class="line">  <span class="string">"""Download the data from source url, unless it's already here.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">      filename: string, name of the file in the directory.</span></span><br><span class="line"><span class="string">      work_directory: string, path to working directory.</span></span><br><span class="line"><span class="string">      source_url: url to download from if file doesn't exist.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">      Path to resulting file.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> gfile.Exists(work_directory):</span><br><span class="line">    gfile.MakeDirs(work_directory)</span><br><span class="line">  filepath = os.path.join(work_directory, filename)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> gfile.Exists(filepath):</span><br><span class="line">    temp_file_name, _ = urlretrieve_with_retry(source_url)</span><br><span class="line">    gfile.Copy(temp_file_name, filepath)</span><br><span class="line">    <span class="keyword">with</span> gfile.GFile(filepath) <span class="keyword">as</span> f:</span><br><span class="line">      size = f.size()</span><br><span class="line">    print(<span class="string">'Successfully downloaded'</span>, filename, size, <span class="string">'bytes.'</span>)</span><br><span class="line">  <span class="keyword">return</span> filepath</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>
                      <strong>输出</strong>：分类结果，0~9之间的一个数</p>
                    <hr>
                    <p>
                      <strong>LeNet-5结构是固定了的：</strong>输入层为32*32的图片，也就是相当于1024个神经元。(我们直接调用TF包的数据集获取函数即可，实现见上述代码)</p>
                    <figure class="highlight python">
                      <table>
                        <tr>
                          <td class="gutter">
                            <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre>
                          </td>
                          <td class="code">
                            <pre><span class="line"><span class="comment">#获取训练集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)python</span><br><span class="line"><span class="comment">#同时创建一个session准备开始干活</span></span><br><span class="line"><span class="comment">#交互式session</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br></pre>
                          </td>
                        </tr>
                      </table>
                    </figure>
                    <p>
                      <strong>C1层：</strong>paper作者，选择6个特征卷积核，然后卷积核大小选择5*5，这样我们可以得到6个特征图，然后每个特征图的大小为32-5+1=28，也就是神经元的个数由1024减小到了28*28=784。
                      <br>
                      <figure class="highlight python">
                        <table>
                          <tr>
                            <td class="gutter">
                              <pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre>
                            </td>
                            <td class="code">
                              <pre><span class="line"><span class="comment">#已将28*28的图片展开成行向量，None代表该维度上数量不确定，</span></span><br><span class="line"><span class="comment"># 此处指的是取样的图像数量不确定</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#图片的标签</span></span><br><span class="line">y_label = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>,<span class="number">10</span>])</span><br></pre>
                            </td>
                          </tr>
                        </table>
                      </figure>
                    </p>

                  </div>

                  <div>
                    <ul class="post-copyright">
                      <li class="post-copyright-author">
                        <strong>本文作者：</strong>
                        十曰立
                      </li>
                      <li class="post-copyright-link">
                        <strong>本文链接：</strong>
                        <a href="http://www.jianshu.com/u/a08f88f9ed9d/2017/12/18/CNN/CNN TensorFlow实现/"
                                                                                                        title="CNN TensorFlow实现">http://www.jianshu.com/u/a08f88f9ed9d/2017/12/18/CNN/CNN
                          TensorFlow实现/</a>
                      </li>
                      <li class="post-copyright-license">
                        <strong>版权声明： </strong>
                        本博客所有文章除特别声明外，均采用
                        <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/"
                                                                                                        rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
                      </li>
                    </ul>

                  </div>

                  <div>

                    <div>

                      <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束
                        <i class="fa fa-paw"></i>感谢您的阅读-------------</div>

                    </div>

                  </div>
                  <footer class="post-footer">

                    <div class="post-nav">
                      <div class="post-nav-next post-nav-item">

                        <a href="/2017/12/18/CNN/第三周《卷积神经网络-目标检测》/" rel="next" title="第三周《卷积神经网络-目标检测》">
                          <i class="fa fa-chevron-left"></i> 第三周《卷积神经网络-目标检测》
                        </a>

                      </div>

                      <span class="post-nav-divider"></span>

                      <div class="post-nav-prev post-nav-item">

                        <a href="/2017/12/18/CNN/CNN网络架构变迁史/" rel="prev" title="CNN网络架构变迁史">
                          CNN网络架构变迁史
                          <i class="fa fa-chevron-right"></i>
                        </a>

                      </div>
                    </div>

                  </footer>
                </div>

              </article>

              <div class="post-spread">

              </div>
            </div>

          </div>

        </div>

        <div class="sidebar-toggle">
          <div class="sidebar-toggle-line-wrap">
            <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
            <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
            <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
          </div>
        </div>

        <aside id="sidebar" class="sidebar">

          <div class="sidebar-inner">

            <ul class="sidebar-nav motion-element">
              <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
                文章目录
              </li>
              <li class="sidebar-nav-overview" data-target="site-overview-wrap">
                站点概览
              </li>
            </ul>

            <section class="site-overview-wrap sidebar-panel">
              <div class="site-overview">
                <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">

                  <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="十曰立"
                  />

                  <p class="site-author-name" itemprop="name">十曰立</p>
                  <p class="site-description motion-element" itemprop="description">处在人工智能的洪流之中...</p>
                </div>

                <nav class="site-state motion-element">

                  <div class="site-state-item site-state-posts">

                    <a href="/archives">

                      <span class="site-state-item-count">44</span>
                      <span class="site-state-item-name">日志</span>
                    </a>
                  </div>

                  <div class="site-state-item site-state-categories">
                    <a href="/categories/index.html">
                      <span class="site-state-item-count">5</span>
                      <span class="site-state-item-name">分类</span>
                    </a>
                  </div>

                </nav>

                <div class="links-of-author motion-element">

                </div>

              </div>
            </section>

            <!--noindex-->
            <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
              <div class="post-toc">

                <div class="post-toc-content">
                  <ol class="nav">
                    <li class="nav-item nav-level-1">
                      <a class="nav-link" href="#LeNet，1998年（开山鼻祖）；">
                        <span class="nav-number">1.</span>
                        <span class="nav-text">
                          LeNet，1998年（开山鼻祖）；</span>
                      </a>
                      <ol class="nav-child">
                        <li class="nav-item nav-level-3">
                          <a class="nav-link" href="#非线性：">
                            <span class="nav-number">1.0.1.</span>
                            <span class="nav-text">

                              非线性：</span>
                          </a>
                        </li>
                        <li class="nav-item nav-level-3">
                          <a class="nav-link" href="#池化">
                            <span class="nav-number">1.0.2.</span>
                            <span class="nav-text">
                              池化</span>
                          </a>
                        </li>
                        <li class="nav-item nav-level-3">
                          <a class="nav-link" href="#全连接层">
                            <span class="nav-number">1.0.3.</span>
                            <span class="nav-text">
                              全连接层</span>
                          </a>
                        </li>
                        <li class="nav-item nav-level-3">
                          <a class="nav-link" href="#得开始训练啦！！！">
                            <span class="nav-number">1.0.4.</span>
                            <span class="nav-text">
                              得开始训练啦！！！</span>
                          </a>
                        </li>
                      </ol>
                    </li>
                    <li class="nav-item nav-level-2">
                      <a class="nav-link" href="#gt-小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事，客官请移步">
                        <span class="nav-number">1.1.</span>
                        <span class="nav-text">
                          >小结：上面的卷积核有些是训练出来的，我们可以直接使用的呐！比如下面这位大神就用其中一个卷积核做了一件了不得的事， 客官请移步!

                        </span>
                      </a>
                    </li>
                  </ol>
                  </li>
                  <li class="nav-item nav-level-1">
                    <a class="nav-link" href="#可视化卷积神经网络">
                      <span class="nav-number">2.</span>
                      <span class="nav-text">
                        可视化卷积神经网络</span>
                    </a>
                  </li>
                  <li class="nav-item nav-level-1">
                    <a class="nav-link" href="#LeNet-5实现（TensorFlow）">
                      <span class="nav-number">3.</span>
                      <span class="nav-text">
                        LeNet-5实现（TensorFlow）</span>
                    </a>
                  </li>
                  </ol>
                </div>

              </div>
            </section>
            <!--/noindex-->

          </div>
        </aside>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy;
          <span itemprop="copyrightYear">2018</span>
          <span class="with-love">
            <i class="fa fa-user"></i>
          </span>
          <span class="author" itemprop="copyrightHolder">十曰立</span>

          <span class="post-meta-divider">|</span>
          <span class="post-meta-item-icon">
            <i class="fa fa-area-chart"></i>
          </span>

          <span class="post-meta-item-text">Site words total count&#58;</span>

          <span title="Site words total count">116.8k</span>

        </div>

        <!-- <div class="powered-by">footer.powered</div>
-->

        <span class="post-meta-divider">|</span>

        <div class="theme-info">footer.theme &mdash;
          <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>

        | 本页点击
        <span id="busuanzi_value_page_pv"></span> 次 | 本站总点击
        <span id="busuanzi_value_site_pv"></span> 次 | 您是第
        <span id="busuanzi_value_site_uv"></span> 位访客
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">


        </script>

        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">


        </script>

      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>

    </div>

  </div>

  <script type="text/javascript">
    if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
      window.Promise = null;
    }

  </script>

  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>

  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
  <script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>

  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>

  <script>
    (function() {
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();

  </script>

</body>

</html>
